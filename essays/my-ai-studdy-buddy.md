---
layout: essay
type: essay
title: "My AI Study Buddy"
# All dates must be YYYY-MM-DD format!
date: 2024-05-3
published: True
labels:
  - Software Engineering
  - Artificial Intelligence
---

<img width="800px" class="rounded float-left pe-4" src="img/openai.png">

### I. Introduction
AI has been an extremely helpful tool for me not just for this class, but for a variety of other classes as well. I use AI such as ChatGPT to guide me in the right direction. For example, if I'm writing an essay. I might ask ChatGPT to assist in spelling and grammatical checks, or I might ask it for ideas on what I should research if I don't know where to start. AI has helped me understand software engineering concepts as well such as design patterns and error handling. I have mainly used ChatGPT, but I have recently started using Github Copilot for my final project.

### II. Personal Experience with AI:
I have used AI in class this semester in the following areas:

1. **In-class practice WODs:** I mainly used ChatGPT to get me started in the right direction and error handling. How I will typically handle a WOD of any sort (practice, in-class, or experiences) is that I'll write as much code as I can by myself, then if there was a particular step or instruction that I didn't fully understand, I would copy and paste that step into ChatGPT which was usually right about 70% of the time. Sometimes I didn't know what I should be doing at all, so I would explain to ChatGPT what I'm trying to accomplish and it would then give me a general idea of what I should be doing. The code it would spit out usually needed some tweaking.


2. **In-class WODs:** As stated in the previous paragraph, I used ChatGPT to help me get started and for handling errors in my code. Much of what I said in the previous paragraph applies here as well.


3. **Essays**: ChatGPT was mainly used for spelling and grammar checks, until the very last essay which was to reflect on the design patterns we used throughout the semester. I had no idea what design patterns even were, so I did a little research on them. I found that there were many design patters and I just couldn't wrap my head around them, nor did I really have the time to study all of them and see how it applies to my code. I just simply asked Github Copilot to look through my final project and see if there were any design patterns that I used. It gave me a few patterns called the container component pattern and the module pattern. These were patterns that seemed very familiar to me, because it sounded just like OOP.


4. **Final project:** While ChatGPT was my main "tutor" so to speak, I started using Github Copilot for my final project. Github Copilot's much more useful because it has access to my project and can give me more specific advice. I am responsible for the home page, leaderboard and goals pages and Github Copilot has been invaluable to me, specifically in assisting me with the goals page. I mainly used it for the backend portion of the webpages, because backend development is still a bit of a challenge to me. For example, I didn't really understand collections all that well, and the goals page needed a collection of goals that the user would add and modify from. I have been going back and forth with Copilot to help me initialize the collection and how to add and modify goals.

   
5. **Writing code:** As mentioned previously, Github Copilot was specifically responsible for the code that adds to the collection of goals in my final project. The code it gave me is very similar to what we learned in the experience WODS so it wasn't too difficult to understand, I just needed a little help getting started.


### III. Impact on Learning and Understanding:
I think that ChatGPT and Github Copilot are incredible learning assistant tools, and it can only improve as time goes on. however, I must be careful using it too much as a crutch. It can be a double-edged sword because on one hand, you can easily get answers tailored to your specific program in an instant (whether it's an accurate answer or not is still up to us to decide for the time being), but on the other hand I am missing out learning and debugging code on my own. You only really learn after you make your own mistakes and figure out how to improve on your own, instead of figuring out mistakes an AI made, because you KNOW how this code should work and what you want it to do.

### IV. Practical Applications:
So I've covered one practical use of AI, are there any other uses I can think of? The only other use of AI that I've really been exposed to is the use of AI in the video game modding community. When we think of AI in gaming, we usually think of the AI that controls the various non-playable characters (NPCs) in the game, or a "director" of a sort to guide or hinder the player depending on the player's performance. This type of AI has a finite number of responses to the player's actions, and you could essentially "learn" how the AI works, predict what it's going to do next, and possibly exploit it. But what if AI had a more dynamic role in the game? Mantella, a mod for Skyrim, created by Art from the Machine, integrates ChatGPT, xVASynth, and Whisper to create new dialogue on the fly for various characters in the game, even your own if you decide to provide voice samples. It's still rough around the edges, but this would allow players to truly have their own unique playthroughs of the same game, and opens up many more possibilities for AI integration in the video game industry. This also brings up some ethical issues, such as the voice actors who didn't provide consent for their voices to be used this way and how it could negatively impact their careers. Players could potentially develop "relationships" with these AI characters now that they feel more "real." And how far are we going to take this? Are we going to use AI to generate new characters and levels in games? Could this affect game designers further down the line? Video games are an art form, and could it really be considered art if there is no human touch to it? Linked below is the trailer for Mantella.

[![Mantella](https://staticdelivery.nexusmods.com/mods/1704/images/98631/98631-1692410212-346989320.png)](https://www.youtube.com/watch?v=FLmbd48r2Wo)

### V. Challenges and Opportunities:
I think the main challenge with AI in software engineering is its reliability. It only has the answers some times and other times it will give you completely garbage code that you would then have to spend more time understanding and debugging it. Another issue with AI is that AI doesn't code for longevity. We had a debate about AI usage in our last class, and our classmate Victor brought up a very good point that while AI is good at writing smaller chunks of the application (when it is right, anyways), it does not have the foresight to account for any future issues the project might encounter as it gets bigger and more complex. Another software engineer is eventually going to have to maintain this code, and if it's not written in a way that is understandable to AI, but not to us, then we would just be hindering them in the long run. I'm not sure if AI can really "learn" this skill, but only time will tell for now.

### VI. Comparative Analysis:
If we're to compare traditional teaching methods and vs AI teaching methods, I would say that AI is best suited for quick and dirty answers, while traditional methods are best for deep dives into new topics and giving you more hands-on learning. I like to think of AI as a quick crash course or a more "advanced" wikipedia page into a new topic, but a classroom is where you can apply that knowledge and speak to others who have real experience in their fields. However, sometimes the information can get a little too overwhelming in a classroom setting, so AI can be there to help you better digest the information by giving you new perspectives or putting it into words that can be better understood by students.

### VII. Future Considerations:
Whether we like it or not, AI is here to stay and students will use it no matter how hard teachers may crack down on it. In my opinion, it would be best to encourage AI usage, but to also reminds students that it's not the fast lane to knowledge. We must think critically about the information AI gives us, because an AI may end up slowing us down in the long run if we're consistently being given wrong information. I personally find it easier to learn new concepts with a buddy, and having ChatGPT being that study buddy can be helpful at times.

### VIII. Conclusion:
Ultimately, I believe that AI can be a net positive if used responsibly. It helps me learn new concepts in a digestible way, provides meaningful examples, and gives me advice tailored to my specific project. In my opinion, AI usage should be encouraged in the classroom, but with the caveat that it should not be used as a crutch. This would apply to any class, not just software engineering.